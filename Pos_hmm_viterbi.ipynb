{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#POS Tagging Algorithm - HMM\n","\n","Hidden Markov Model based algorithm is used to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word.\n","\n","In other words, to every word w, assign the tag t that maximises the likelihood P(t/w). Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n","\n","P(w/t) is basically the probability that given a tag (say NN), what is the probability of it being w (say 'building'). This can be computed by computing the fraction of all NNs which are equal to w, i.e.\n","\n","P(w/t) = count(w, t) / count(t).\n","\n","The term P(t) is the probability of tag t, and in a tagging task, we assume that a tag will depend only on the previous tag. In other words, the probability of a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.).\n","\n","Given the penn treebank tagged dataset, we can compute the two terms P(w/t) and P(t) and store them in two large matrices. The matrix of P(w/t) will be sparse, since each word will not be seen with most tags ever, and those terms will thus be zero."],"metadata":{"id":"qCzzAXAovDKk"}},{"cell_type":"markdown","source":["#Viterbi Algorithm\n","Let's now use the computed probabilities P(w, tag) and P(t2, t1) to assign tags to each word in the document. We'll run through each word w and compute P(tag/w)=P(w/tag).P(tag) for each tag in the tag set, and then assign the tag having the max P(tag/w).\n","\n","We'll store the assigned tags in a list of tuples, similar to the list 'train_tagged_words'. Each tuple will be a (token, assigned_tag). As we progress further in the list, each tag to be assigned will use the tag of the previous token.\n","\n","Note: P(tag|start) = P(tag|'.')"],"metadata":{"id":"CJhLcn-SvxK_"}},{"cell_type":"code","source":["#method-1\n","import nltk\n","from nltk.corpus import treebank\n","from sklearn.metrics import accuracy_score\n","nltk.download('treebank')\n","\n","# Load the Penn Treebank dataset\n","dataset = treebank.tagged_sents()\n","\n","# Split the dataset into training and testing sets\n","train_data = dataset[:3500]\n","test_data = dataset[3500:]\n","\n","# Define the HMM-based POS tagger using the built-in module in NLTK\n","tagger = nltk.tag.HiddenMarkovModelTagger.train(train_data)\n","\n","# Apply the POS tagger on the test set using the Viterbi algorithm built-in module in NLTK\n","predicted_tags = []\n","actual_tags = []\n","\n","for sent in test_data:\n","    words = [word for word, tag in sent]\n","    tags = [tag for word, tag in sent]\n","    predicted_tags += [tag for word, tag in tagger.tag(words)]\n","    actual_tags += tags\n","\n","# Evaluate the accuracy of the POS tagger\n","accuracy = accuracy_score(actual_tags, predicted_tags)\n","print(f\"Accuracy: {accuracy:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdJEnsT7dT0t","outputId":"3cc8fddf-64ee-47e9-84d6-4ec03bab917b","executionInfo":{"status":"ok","timestamp":1682485664748,"user_tz":-330,"elapsed":12580,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 89.89%\n"]}]},{"cell_type":"code","source":["#method-2\n","\n","import nltk\n","nltk.download('treebank')\n","from nltk.corpus import treebank\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MboeYpaEsTJe","outputId":"2488542e-ad1c-4328-e6ce-4ee1021c15e5","executionInfo":{"status":"ok","timestamp":1682485673655,"user_tz":-330,"elapsed":581,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Split the corpus into training and testing sets\n","train_sents = treebank.tagged_sents()[:int(len(treebank.tagged_sents())*0.9)]\n","test_sents = treebank.tagged_sents()[int(len(treebank.tagged_sents())*0.9):]\n"],"metadata":{"id":"-IFLJ7Aas0cq","executionInfo":{"status":"ok","timestamp":1682485682387,"user_tz":-330,"elapsed":7730,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from nltk.tag import HiddenMarkovModelTagger\n","\n","# Train the HMM model\n","hmm_tagger = HiddenMarkovModelTagger.train(train_sents)\n"],"metadata":{"id":"y8Wp-d6Ks1wp","executionInfo":{"status":"ok","timestamp":1682485685316,"user_tz":-330,"elapsed":2933,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Tag the test set using the Viterbi algorithm\n","hmm_pred = hmm_tagger.tag_sents([sent for sent in test_sents])\n","\n","# Evaluate the accuracy of the model\n","hmm_acc = hmm_tagger.evaluate(test_sents)\n","print(f\"HMM Accuracy: {hmm_acc:.2%}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqxRC86vs3kY","outputId":"c57a3b0e-9ecb-4a6d-8f71-783c6f50c456","executionInfo":{"status":"ok","timestamp":1682485768329,"user_tz":-330,"elapsed":15454,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-e0392ba13b42>:5: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  hmm_acc = hmm_tagger.evaluate(test_sents)\n"]},{"output_type":"stream","name":"stdout","text":["HMM Accuracy: 89.93%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AT5qWmsZs5Rq","executionInfo":{"status":"aborted","timestamp":1682485685318,"user_tz":-330,"elapsed":7,"user":{"displayName":"navadeep chowdary","userId":"17512258322492939931"}}},"execution_count":null,"outputs":[]}]}